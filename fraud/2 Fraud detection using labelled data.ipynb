{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fraud detection using labelled data\n",
    "Now that you're familiar with the main challenges of fraud detection, you're about to learn how to flag fraudulent transactions with supervised learning. You will use classifiers, adjust them and compare them to find the most efficient fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Natural hit rate\n",
    "In this exercise, you'll again use credit card transaction data. The features and labels are similar to the data in the previous chapter, and the data is heavily imbalanced. We've given you features X and labels y to work with already, which are both numpy arrays.\n",
    "\n",
    "First you need to explore how prevalent fraud is in the dataset, to understand what the \"natural accuracy\" is, if we were to predict everything as non-fraud. It's is important to understand which level of \"accuracy\" you need to \"beat\" in order to get a better prediction than by doing nothing. In the following exercises, you'll create our first random forest classifier for fraud detection. That will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.00990099009901\n"
     ]
    }
   ],
   "source": [
    "# Import pandas and read csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def prep_data(df):\n",
    "    X = df.iloc[:, 1:29]\n",
    "    X = np.array(X).astype(np.float)\n",
    "    y = df.iloc[:, 29]\n",
    "    y=np.array(y).astype(np.float)\n",
    "    return X,y\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"data/creditcard_data.csv\").drop('Unnamed: 0',axis=1)\n",
    "X, y = prep_data(df)\n",
    "\n",
    "# Count the total number of observations from the length of y\n",
    "total_obs = len(y)\n",
    "\n",
    "# Count the total number of non-fraudulent observations\n",
    "non_fraud = [i for i in y if i == 0]\n",
    "count_non_fraud = non_fraud.count(0)\n",
    "\n",
    "# Calculate the percentage of non fraud observations in the dataset\n",
    "percentage = (float(count_non_fraud)/float(total_obs)) * 100\n",
    "\n",
    "# Print the percentage: this is our \"natural accuracy\" by doing nothing\n",
    "print(percentage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tells us that by doing nothing, we would be correct in 95.9% of the cases. So now you understand, that if we get an accuracy of less than this number, our model does not actually add any value in predicting how many cases are correct. Let's see how a random forest does in predicting fraud in our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classifier - part 1\n",
    "Let's now create a first random forest classifier for fraud detection. Hopefully you can do better than the baseline accuracy you've just calculated, which was roughly 96%. This model will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises. Let's start first with splitting the data into a test and training set, and defining the Random Forest model. The data available are features X and labels y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import the random forest model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Define the model as the random forest\n",
    "model = RandomForestClassifier(random_state=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classifier - part 2\n",
    "Let's see how our Random Forest model performs without doing anything special to it. The model from the previous exercise is available, and you've already split your data in X_train, y_train, X_test, y_test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986798679867986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
    "\n",
    "# Fit the model to our training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predictions from the test data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy performance metric\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance metrics for the RF model\n",
    "In the previous exercises you obtained an accuracy score for your random forest model. This time, we know accuracy can be misleading in the case of fraud detection. With highly imbalanced fraud data, the AUROC curve is a more reliable performance metric, used to compare different classifiers. Moreover, the classification report tells you about the precision and recall of your model, whilst the confusion matrix actually shows how many fraud cases you can predict correctly. So let's get these performance metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993687707641195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.95      0.95      0.95      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   1    9]]\n"
     ]
    }
   ],
   "source": [
    "# Import the packages to get the different performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Obtain the predictions from our random forest model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You have now obtained more meaningful performance metrics that tell us how well the model performs, given the highly imbalanced data that you're working with. The model predicts 76 cases of fraud, out of which 73 are actual fraud. You have only 3 false positives. This is really good, and as a result you have a very high precision score. You do however, don't catch 18 cases of actual fraud. Recall is therefore not as good as precision. Let's try to improve that in the following exercises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the Precision Recall Curve\n",
    "You can also plot a Precision-Recall curve, to investigate the trade-off between the two in your model. In this curve Precision and Recall are inversely related; as Precision increases, Recall falls and vice-versa. A balance between these two needs to be achieved in your model, otherwise you might end up with many false positives, or not enough actual fraud cases caught. To achieve this and to compare performance, the precision-recall curves come in handy.\n",
    "\n",
    "Your Random Forest Classifier is available as model, and the predictions as predicted. You can simply obtain the average precision score and the PR curve from the sklearn package. The function plot_pr_curve() plots the results for you. Let's give it a try."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_pr_curve(recall, precision, average_precision):\n",
    "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "  plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "  plt.show()\n",
    "\n",
    "# Calculate average precision and the PR curve\n",
    "average_precision = average_precision_score(y_test, predicted)\n",
    "\n",
    "# Obtain precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, predicted)\n",
    "\n",
    "# Plot the recall precision tradeoff\n",
    "plot_pr_curve(recall, precision, average_precision)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ROC curve plots the true positives vs. false positives , for a classifier, as its discrimination threshold is varied. Since, a random method describes a horizontal curve through the unit interval, it has an AUC of 0.5. Minimally, classifiers should perform better than this, and the extent to which they score higher than one another (meaning the area under the ROC curve is larger), they have better expected performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model adjustments\n",
    "A simple way to adjust the random forest model to deal with highly imbalanced fraud data, is to use the class_weights option when defining your sklearn model. However, as you will see, it is a bit of a blunt force mechanism and might not work for your very special case.\n",
    "\n",
    "In this exercise you'll explore the weight = \"balanced_subsample\" mode the Random Forest model from the earlier exercise. You already have split your data in a training and test set, i.e X_train, X_test, y_train, y_test are available. The metrics function have already been imported.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994019933554817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.94      0.90      0.92      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   2    8]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with balanced subsample\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample', random_state=5)\n",
    "\n",
    "# Fit your training model to your training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predicted values and probabilities from the model\n",
    "predicted = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the roc_auc_score, the classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that the model results don't improve drastically. We now have 3 less false positives, but now 19 in stead of 18 false negatives, i.e. cases of fraud we are not catching. If we mostly care about catching fraud, and not so much about the false positives, this does actually not improve our model at all, albeit a simple option to try. In the next exercises you'll see how to more smartly tweak your model to focus on reducing false negatives and catch more fraud."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adjusting your Random Forest to fraud detection\n",
    "In this exercise you're going to dive into the options for the random forest classifier, as we'll assign weights and tweak the shape of the decision trees in the forest. You'll define weights manually, to be able to off-set that imbalance slightly. In our case we have 300 fraud to 7000 non-fraud cases, so by setting the weight ratio to 1:12, we get to a 1/3 fraud to 2/3 non-fraud ratio, which is good enough for training the model on.\n",
    "\n",
    "The data in this exercise has already been split into training and test set, so you just need to focus on defining your model. You can then use the function get_model_results() as a short cut. This function fits the model to your training data, predicts and obtains performance metrics similar to the steps you did in the previous exercises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_model_results(X_train, y_train, X_test, y_test, model):\n",
    "  model.fit(X_train, y_train)\n",
    "  predicted = model.predict(X_test)\n",
    "  probs = model.predict_proba(X_test)\n",
    "  print (classification_report(y_test, predicted))\n",
    "  print (confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.92      1.00      0.95      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1503    2]\n",
      " [   0   10]]\n"
     ]
    }
   ],
   "source": [
    "# Change the model options\n",
    "model = RandomForestClassifier(bootstrap=True, class_weight={0:1, 1:12}, criterion='entropy',\n",
    "\n",
    "\t\t\t# Change depth of model\n",
    "            max_depth=10,\n",
    "\n",
    "\t\t\t# Change the number of samples in leaf nodes\n",
    "            min_samples_leaf=10,\n",
    "\n",
    "\t\t\t# Change the number of trees to use\n",
    "            n_estimators=20, n_jobs=-1, random_state=5)\n",
    "\n",
    "# Run the function get_model_results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see by smartly defining more options in the model, you can obtain better predictions. You have effectively reduced the number of false negatives, i.e. you are catching more cases of fraud, whilst keeping the number of false positives low. In this exercise you've manually changed the options of the model. There is a smarter way of doing it, by using GridSearchCV, which you'll see in the next exercise!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GridSearchCV to find optimal parameters\n",
    "In this exercise you're going to tweak our model in a less \"random\" way, but use GridSearchCV to do the work for you.\n",
    "\n",
    "With GridSearchCV you can define which performance metric to score the options on. Since for fraud detection we are mostly interested in catching as many fraud cases as possible, you can optimize your model settings to get the best possible Recall score. If you also cared about reducing the number of false positives, you could optimize on F1-score, this gives you that nice Precision-Recall trade-off."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "{'criterion': 'gini',\n 'max_depth': 4,\n 'max_features': 'log2',\n 'n_estimators': 30}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter sets to test\n",
    "param_grid = {'n_estimators': [1, 30], 'max_features': ['auto', 'log2'],  'max_depth': [4, 8], 'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Define the model to use\n",
    "model = RandomForestClassifier(random_state=5)\n",
    "\n",
    "# Combine the parameter sets with the defined model\n",
    "CV_model = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='recall', n_jobs=-1)\n",
    "\n",
    "# Fit the model to our training data and obtain best parameters\n",
    "CV_model.fit(X_train, y_train)\n",
    "CV_model.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model results using GridSearchCV\n",
    "You discovered that the best parameters for your model are that the split criterion should be set to 'gini', the number of estimators (trees) should be 30, the maximum depth of the model should be 8 and the maximum features should be set to \"log2\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.95      0.95      0.95      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   1    9]]\n"
     ]
    }
   ],
   "source": [
    "# Input the optimal parameters in the model\n",
    "model = RandomForestClassifier(class_weight={0:1,1:12}, criterion='gini',\n",
    "            max_depth=8, max_features='log2', min_samples_leaf=10, n_estimators=30, n_jobs=-1, random_state=5)\n",
    "\n",
    "# Get results from your model\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You've managed to improve your model even further. The number of false positives has now been slightly reduced even further, which means we are catching more cases of fraud. However, you see that the number of false positives actually went up. That is that Precision-Recall trade-off in action. To decide which final model is best, you need to take into account how bad it is not to catch fraudsters, versus how many false positives the fraud analytics team can deal with. Ultimately, this final decision should be made by you and the fraud team together."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic Regression\n",
    "In this last lesson you'll combine three algorithms into one model with the VotingClassifier. This allows us to benefit from the different aspects from all models, and hopefully improve overall performance and detect more fraud. The first model, the Logistic Regression, has a slightly higher recall score than our optimal Random Forest model, but gives a lot more false positives. You'll also add a Decision Tree with balanced weights to it. The data is already split into a training and test set, i.e. X_train, y_train, X_test, y_test are available.\n",
    "\n",
    "In order to understand how the Voting Classifier can potentially improve your original model, you should check the standalone results of the Logistic Regression model first."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.57      0.80      0.67        10\n",
      "\n",
      "    accuracy                           0.99      1515\n",
      "   macro avg       0.79      0.90      0.83      1515\n",
      "weighted avg       1.00      0.99      1.00      1515\n",
      "\n",
      "[[1499    6]\n",
      " [   2    8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the Logistic Regression model with weights\n",
    "model = LogisticRegression(class_weight={0:1, 1:15}, random_state=5)\n",
    "\n",
    "# Get the model results\n",
    "get_model_results(X_train, y_train, X_test, y_test, model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see the Logistic Regression has quite different performance from the Random Forest. More false positives, but also a better Recall. It will therefore will a useful addition to the Random Forest in an ensemble model. Let's give that a try"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Voting Classifier\n",
    "Let's now combine three machine learning models into one, to improve our Random Forest fraud detection model from before. You'll combine our usual Random Forest model, with the Logistic Regression from the previous exercise, with a simple Decision Tree. You can use the short cut get_model_results() to see the immediate result of the ensemble model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.94      0.90      0.92      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   2    8]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "def get_model_results(X_train, y_train, X_test, y_test, model):\n",
    "  model.fit(X_train, y_train)\n",
    "  predicted = model.predict(X_test)\n",
    "  #probs = model.predict_proba(X_test)\n",
    "  print (classification_report(y_test, predicted))\n",
    "  print (confusion_matrix(y_test, predicted))\n",
    "\n",
    "\n",
    "# Import the packages\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the three classifiers to use in the ensemble\n",
    "clf1 = LogisticRegression(class_weight={0:1, 1:15}, random_state=5, n_jobs=1)\n",
    "clf2 = RandomForestClassifier(class_weight={0:1, 1:12}, criterion='gini', max_depth=8, max_features='log2',\n",
    "            min_samples_leaf=10, n_estimators=30, n_jobs=1, random_state=5)\n",
    "clf3 = DecisionTreeClassifier(random_state=5, class_weight=\"balanced\")\n",
    "\n",
    "# Combine the classifiers in the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('dt', clf3)], voting='hard', n_jobs=1)\n",
    "\n",
    "# Get the results\n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You see that by combining the classifiers, you can take the best of multiple models. You've increased the cases of fraud you are catching from 76 to 78, and you only have 5 extra false positives in return. If you do care about catching as many fraud cases as you can, whilst keeping the false positives low, this is a pretty good trade-off. The Logistic Regression as a standalone was quite bad in terms of false positives, and the Random Forest was worse in terms of false negatives. By combining these together you indeed managed to improve performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Adjust weights within the Voting Classifier\n",
    "You've just seen that the Voting Classifier allows you to improve your fraud detection performance, by combining good aspects from multiple models. Now let's try to adjust the weights we give to these models. By increasing or decreasing weights you can play with how much emphasis you give to a particular model relative to the rest. This comes in handy when a certain model has overall better performance than the rest, but you still want to combine aspects of the others to further improve your results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.95      1.00      0.98      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   0   10]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alejandro.robles/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Define the ensemble model\n",
    "ensemble_model = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='soft', weights=[1, 4, 1], flatten_transform=True)\n",
    "\n",
    "# Get results\n",
    "get_model_results(X_train, y_train, X_test, y_test, ensemble_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The weight option allows you to play with the individual models to get the best final mix for your fraud detection model. Now that you have finalized fraud detection with supervised learning, let's have a look at how fraud detetion can be done when you don't have any labels to train on.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}