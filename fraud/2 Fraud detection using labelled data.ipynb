{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fraud detection using labelled data\n",
    "Now that you're familiar with the main challenges of fraud detection, you're about to learn how to flag fraudulent transactions with supervised learning. You will use classifiers, adjust them and compare them to find the most efficient fraud detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Natural hit rate\n",
    "In this exercise, you'll again use credit card transaction data. The features and labels are similar to the data in the previous chapter, and the data is heavily imbalanced. We've given you features X and labels y to work with already, which are both numpy arrays.\n",
    "\n",
    "First you need to explore how prevalent fraud is in the dataset, to understand what the \"natural accuracy\" is, if we were to predict everything as non-fraud. It's is important to understand which level of \"accuracy\" you need to \"beat\" in order to get a better prediction than by doing nothing. In the following exercises, you'll create our first random forest classifier for fraud detection. That will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.00990099009901\n"
     ]
    }
   ],
   "source": [
    "# Import pandas and read csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def prep_data(df):\n",
    "    X = df.iloc[:, 1:29]\n",
    "    X = np.array(X).astype(np.float)\n",
    "    y = df.iloc[:, 29]\n",
    "    y=np.array(y).astype(np.float)\n",
    "    return X,y\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv(\"data/creditcard_data.csv\").drop('Unnamed: 0',axis=1)\n",
    "X, y = prep_data(df)\n",
    "\n",
    "# Count the total number of observations from the length of y\n",
    "total_obs = len(y)\n",
    "\n",
    "# Count the total number of non-fraudulent observations\n",
    "non_fraud = [i for i in y if i == 0]\n",
    "count_non_fraud = non_fraud.count(0)\n",
    "\n",
    "# Calculate the percentage of non fraud observations in the dataset\n",
    "percentage = (float(count_non_fraud)/float(total_obs)) * 100\n",
    "\n",
    "# Print the percentage: this is our \"natural accuracy\" by doing nothing\n",
    "print(percentage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tells us that by doing nothing, we would be correct in 95.9% of the cases. So now you understand, that if we get an accuracy of less than this number, our model does not actually add any value in predicting how many cases are correct. Let's see how a random forest does in predicting fraud in our data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classifier - part 1\n",
    "Let's now create a first random forest classifier for fraud detection. Hopefully you can do better than the baseline accuracy you've just calculated, which was roughly 96%. This model will serve as the \"baseline\" model that you're going to try to improve in the upcoming exercises. Let's start first with splitting the data into a test and training set, and defining the Random Forest model. The data available are features X and labels y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Import the random forest model from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split your data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Define the model as the random forest\n",
    "model = RandomForestClassifier(random_state=5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Random Forest Classifier - part 2\n",
    "Let's see how our Random Forest model performs without doing anything special to it. The model from the previous exercise is available, and you've already split your data in X_train, y_train, X_test, y_test."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986798679867986\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_curve\n",
    "\n",
    "# Fit the model to our training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain predictions from the test data\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Print the accuracy performance metric\n",
    "print(accuracy_score(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Performance metrics for the RF model\n",
    "In the previous exercises you obtained an accuracy score for your random forest model. This time, we know accuracy can be misleading in the case of fraud detection. With highly imbalanced fraud data, the AUROC curve is a more reliable performance metric, used to compare different classifiers. Moreover, the classification report tells you about the precision and recall of your model, whilst the confusion matrix actually shows how many fraud cases you can predict correctly. So let's get these performance metrics."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9993687707641195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.95      0.95      0.95      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   1    9]]\n"
     ]
    }
   ],
   "source": [
    "# Import the packages to get the different performance metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Obtain the predictions from our random forest model\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "# Predict probabilities\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the ROC curve, classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You have now obtained more meaningful performance metrics that tell us how well the model performs, given the highly imbalanced data that you're working with. The model predicts 76 cases of fraud, out of which 73 are actual fraud. You have only 3 false positives. This is really good, and as a result you have a very high precision score. You do however, don't catch 18 cases of actual fraud. Recall is therefore not as good as precision. Let's try to improve that in the following exercises."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plotting the Precision Recall Curve\n",
    "You can also plot a Precision-Recall curve, to investigate the trade-off between the two in your model. In this curve Precision and Recall are inversely related; as Precision increases, Recall falls and vice-versa. A balance between these two needs to be achieved in your model, otherwise you might end up with many false positives, or not enough actual fraud cases caught. To achieve this and to compare performance, the precision-recall curves come in handy.\n",
    "\n",
    "Your Random Forest Classifier is available as model, and the predictions as predicted. You can simply obtain the average precision score and the PR curve from the sklearn package. The function plot_pr_curve() plots the results for you. Let's give it a try."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def plot_pr_curve(recall, precision, average_precision):\n",
    "  plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "  plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "  plt.xlabel('Recall')\n",
    "  plt.ylabel('Precision')\n",
    "  plt.ylim([0.0, 1.05])\n",
    "  plt.xlim([0.0, 1.0])\n",
    "  plt.title('2-class Precision-Recall curve: AP={0:0.2f}'.format(average_precision))\n",
    "  plt.show()\n",
    "\n",
    "# Calculate average precision and the PR curve\n",
    "average_precision = average_precision_score(y_test, predicted)\n",
    "\n",
    "# Obtain precision and recall\n",
    "precision, recall, _ = precision_recall_curve(y_test, predicted)\n",
    "\n",
    "# Plot the recall precision tradeoff\n",
    "plot_pr_curve(recall, precision, average_precision)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The ROC curve plots the true positives vs. false positives , for a classifier, as its discrimination threshold is varied. Since, a random method describes a horizontal curve through the unit interval, it has an AUC of 0.5. Minimally, classifiers should perform better than this, and the extent to which they score higher than one another (meaning the area under the ROC curve is larger), they have better expected performance."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model adjustments\n",
    "A simple way to adjust the random forest model to deal with highly imbalanced fraud data, is to use the class_weights option when defining your sklearn model. However, as you will see, it is a bit of a blunt force mechanism and might not work for your very special case.\n",
    "\n",
    "In this exercise you'll explore the weight = \"balanced_subsample\" mode the Random Forest model from the earlier exercise. You already have split your data in a training and test set, i.e X_train, X_test, y_train, y_test are available. The metrics function have already been imported.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994019933554817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      1505\n",
      "         1.0       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           1.00      1515\n",
      "   macro avg       0.94      0.90      0.92      1515\n",
      "weighted avg       1.00      1.00      1.00      1515\n",
      "\n",
      "[[1504    1]\n",
      " [   2    8]]\n"
     ]
    }
   ],
   "source": [
    "# Define the model with balanced subsample\n",
    "model = RandomForestClassifier(class_weight='balanced_subsample', random_state=5)\n",
    "\n",
    "# Fit your training model to your training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Obtain the predicted values and probabilities from the model\n",
    "predicted = model.predict(X_test)\n",
    "probs = model.predict_proba(X_test)\n",
    "\n",
    "# Print the roc_auc_score, the classification report and confusion matrix\n",
    "print(roc_auc_score(y_test, probs[:,1]))\n",
    "print(classification_report(y_test, predicted))\n",
    "print(confusion_matrix(y_test, predicted))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can see that the model results don't improve drastically. We now have 3 less false positives, but now 19 in stead of 18 false negatives, i.e. cases of fraud we are not catching. If we mostly care about catching fraud, and not so much about the false positives, this does actually not improve our model at all, albeit a simple option to try. In the next exercises you'll see how to more smartly tweak your model to focus on reducing false negatives and catch more fraud."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}